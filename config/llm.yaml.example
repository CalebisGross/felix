# Felix LLM Provider Configuration

# Primary LLM provider (will be tried first)
primary:
  type: "lm_studio"  # lm_studio, anthropic, or gemini

  # LM Studio settings (for local LLMs)
  base_url: "http://localhost:1234/v1"
  model: "local-model"
  timeout: 120

  # Uncomment for Anthropic
  # type: "anthropic"
  # api_key: "${ANTHROPIC_API_KEY}"  # Set via environment variable
  # model: "claude-3-5-sonnet-20241022"
  # timeout: 120

  # Uncomment for Gemini
  # type: "gemini"
  # api_key: "${GEMINI_API_KEY}"  # Set via environment variable
  # model: "gemini-1.5-flash-latest"
  # timeout: 120

# Fallback providers (tried in order if primary fails)
fallbacks:
  # Example: Use Anthropic if LM Studio is down
  # - type: "anthropic"
  #   api_key: "${ANTHROPIC_API_KEY}"
  #   model: "claude-3-5-sonnet-20241022"

  # Example: Use Gemini as last resort
  # - type: "gemini"
  #   api_key: "${GEMINI_API_KEY}"
  #   model: "gemini-1.5-flash-latest"

# Router settings
router:
  retry_on_rate_limit: false  # Don't try fallbacks on rate limits
  verbose_logging: false      # Detailed router logs

# Cost tracking (applies to cloud providers)
cost_tracking:
  enabled: true
  daily_limit_usd: 50.00    # Maximum spend per day
  monthly_limit_usd: 500.00  # Maximum spend per month
  alert_threshold: 0.80      # Alert at 80% of limit

# Model aliases (shortcuts for common configurations)
aliases:
  sonnet: "claude-3-5-sonnet-20241022"
  opus: "claude-3-opus-20240229"
  haiku: "claude-3-haiku-20240307"
  gemini-pro: "gemini-1.5-pro-latest"
  gemini-flash: "gemini-1.5-flash-latest"
